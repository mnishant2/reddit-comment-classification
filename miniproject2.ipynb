{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "miniproject2_new (4).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xshZcRA48dQl",
        "outputId": "77461298-178b-44df-8ecb-2b7d17f375b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LuCrDxAdeN4D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "import pickle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CV2w6ZF1MITc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ec6bbfe2-0cbc-4238-9ffb-bd0ceb76550f"
      },
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Activation\n",
        "from keras import Model\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils import to_categorical\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vdYz97BU8Mob",
        "outputId": "a636493f-50da-4a04-da1f-3346c929868f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        }
      },
      "source": [
        "import numpy as np\n",
        "from mlxtend.classifier import StackingCVClassifier\n",
        "from nltk import SnowballStemmer, WordNetLemmatizer, PorterStemmer\n",
        "import pandas as pd\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.model_selection import train_test_split\n",
        "import random\n",
        "from sklearn.ensemble import RandomForestClassifier,VotingClassifier,GradientBoostingClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB, GaussianNB,BernoulliNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "import matplotlib.pyplot as plt\n",
        "# from sklearn.decomposition import TruncatedSVD   # too expensive!a\n",
        "import nltk \n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "stop_words = stopwords.words('english')\n",
        "SEED = 15\n",
        "random.seed(SEED)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/six.py:31: DeprecationWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eTqhll58gVx0",
        "colab": {}
      },
      "source": [
        "import fastai\n",
        "from fastai import *\n",
        "from fastai.text import * \n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from functools import partial\n",
        "import io\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Hx96lGvB8Mof",
        "colab": {}
      },
      "source": [
        "def preprocess(text):\n",
        "    token = RegexpTokenizer(r'[a-zA-Z]+')\n",
        "    wnl = WordNetLemmatizer()\n",
        "    ps = SnowballStemmer('english')\n",
        "#     ps = PorterStemmer()\n",
        "    \n",
        "    tokens = token.tokenize(text.lower())\n",
        "    \n",
        "    tokens_l = [wnl.lemmatize(token) for token in tokens]\n",
        "    \n",
        "    tokens_ls = [ps.stem(token) for token in tokens_l]\n",
        "    \n",
        "    return tokens_l # without stemming\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jOup-TEHP65j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# alternate preprocessing for further data cleaning(RESULTED IN REDUCTION IN PERFORMANCE)\n",
        "def remove_one_letter(array):\n",
        "    to_ret = []\n",
        "    \n",
        "    for token in array:\n",
        "        if len(token) > 1:\n",
        "            to_ret.append(token)\n",
        "\n",
        "    return to_ret\n",
        "            \n",
        "\n",
        "def preprocess(text):\n",
        "    token = RegexpTokenizer(r'[a-zA-Z]+')\n",
        "    wnl = WordNetLemmatizer()\n",
        "    ps = SnowballStemmer('english')\n",
        "    text = re.sub(string=text, pattern='http[^-\\s]+youtube\\.[^-\\s]*watch[^-\\s]*', repl='')\n",
        "    \n",
        "    tokens = token.tokenize(text.lower())\n",
        "    \n",
        "    \n",
        "    general_site_protocols = ['https',\n",
        "                             'http',\n",
        "                             'www']\n",
        "    \n",
        "    general_site_names = ['youtube',\n",
        "                          'youtu',\n",
        "                         'wikipedia',\n",
        "                         'reddit',\n",
        "                         'google',\n",
        "                         'wiki']\n",
        "    \n",
        "    general_site_domains = ['com',\n",
        "                           'org',\n",
        "                           'net']    \n",
        "    \n",
        "    \n",
        "    \n",
        "    tokens_more_than_one_char = []\n",
        "    i = 0\n",
        "    for i in range(len(tokens)):\n",
        "        token = tokens[i]\n",
        "        if len(token) > 1 and not ((token in general_site_protocols) \\\n",
        "                                   or (token in general_site_names) \\\n",
        "                                   or (token in general_site_domains)):\n",
        "            tokens_more_than_one_char.append(token)\n",
        "\n",
        "    tokens_l = [wnl.lemmatize(token) for token in tokens_more_than_one_char]\n",
        "    \n",
        "    return tokens_l # without stemming\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9_hmo2TMFc7",
        "colab_type": "text"
      },
      "source": [
        "DATA LOADING+ PREPROCESSING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QHArTGiV8Moi",
        "colab": {}
      },
      "source": [
        "\n",
        "train = pd.read_csv('/content/drive/My Drive/reddit-comment-classification-comp-551/reddit_train.csv')\n",
        "test = pd.read_csv('/content/drive/My Drive/reddit-comment-classification-comp-551/reddit_test.csv')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cHYZpIBr8Mol",
        "colab": {}
      },
      "source": [
        "y_labels_train = train['subreddits'].values\n",
        "x_comments_train = train['comments'].values\n",
        "x_comments_test = test['comments'].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "f3qwza9g8Moo",
        "colab": {}
      },
      "source": [
        "# train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "705OAQIH8Mor",
        "colab": {}
      },
      "source": [
        "labels = np.unique(y_labels_train)\n",
        "labels_to_index = {w: int(np.where(labels==w)[0]) for w in labels}\n",
        "index_to_labels={v:k for k,v in labels_to_index.items()}\n",
        "train['labels'] = train['subreddits'].map(labels_to_index)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rMQZTjFy8Mou",
        "colab": {}
      },
      "source": [
        "y = train['labels'].values\n",
        "# y_train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Jo8xW28e8Moy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "outputId": "5d9aa586-eb6a-4fb7-8a9f-359f79962d06"
      },
      "source": [
        "del train['id']\n",
        "del test['id']\n",
        "\n",
        "train=train.rename(columns={\"comments\": \"text\", \"subreddits\": \"label\"})\n",
        "test=test.rename(columns={\"comments\": \"text\"})\n",
        "cols=train.columns.tolist()\n",
        "print(train.head())\n",
        "print(cols)\n",
        "train=train[[\"label\",\"text\",\"labels\"]]\n",
        "print(train.head())"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                text            label  labels\n",
            "0  Honestly, Buffalo is the correct answer. I rem...           hockey      11\n",
            "1  Ah yes way could have been :( remember when he...              nba      14\n",
            "2  https://youtu.be/6xxbBR8iSZ0?t=40m49s\\n\\nIf yo...  leagueoflegends      12\n",
            "3  He wouldn't have been a bad signing if we woul...           soccer      16\n",
            "4  Easy. You use the piss and dry technique. Let ...            funny       9\n",
            "['text', 'label', 'labels']\n",
            "             label                                               text  labels\n",
            "0           hockey  Honestly, Buffalo is the correct answer. I rem...      11\n",
            "1              nba  Ah yes way could have been :( remember when he...      14\n",
            "2  leagueoflegends  https://youtu.be/6xxbBR8iSZ0?t=40m49s\\n\\nIf yo...      12\n",
            "3           soccer  He wouldn't have been a bad signing if we woul...      16\n",
            "4            funny  Easy. You use the piss and dry technique. Let ...       9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DuOGUFAlU8xY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train['text'] = train['text'].str.replace(\"[^a-zA-Z]\", \" \")\n",
        "test['text'] = test['text'].str.replace(\"[^a-zA-Z]\", \" \")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWCnr6fCVKsn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenized_doc = train['text'].apply(lambda x: x.split())\n",
        "\n",
        "# remove stop-words \n",
        "tokenized_doc = tokenized_doc.apply(lambda x: [item.lower() for item in x if item not in stop_words])\n",
        "\n",
        "# de-tokenization \n",
        "detokenized_doc = [] \n",
        "for i in range(len(train)): \n",
        "    t = ' '.join(tokenized_doc[i]) \n",
        "    detokenized_doc.append(t) \n",
        "\n",
        "train['text'] = detokenized_doc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mO4Q4OB-VPSA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenized_doc = test['text'].apply(lambda x: x.split())\n",
        "\n",
        "# remove stop-words \n",
        "tokenized_doc = tokenized_doc.apply(lambda x: [item.lower() for item in x if item not in stop_words])\n",
        "\n",
        "# de-tokenization \n",
        "detokenized_doc = [] \n",
        "for i in range(len(test)): \n",
        "    t = ' '.join(tokenized_doc[i]) \n",
        "    detokenized_doc.append(t) \n",
        "\n",
        "test['text'] = detokenized_doc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRwYO19XVUC9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "7b409b11-1fa3-40b1-97ea-369918236369"
      },
      "source": [
        "df_trn, df_val = train_test_split(train,test_size = 0.1, random_state=SEED,shuffle=False)\n",
        "x_train=df_trn['text'].values\n",
        "y_train=df_trn['labels'].values\n",
        "x_val=df_val['text'].values\n",
        "y_val=df_val['labels'].values\n",
        "df_trn=df_trn.reset_index(drop = True)\n",
        "df_val=df_val.reset_index(drop = True)\n",
        "print(len(df_val))\n",
        "sample=int(0.5*len(df_val))\n",
        "print(sample)\n",
        "df_val1=df_val[:sample]\n",
        "df_val2=df_val[sample:]\n",
        "print(len(df_val2),len(df_val1))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7000\n",
            "3500\n",
            "3500 3500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TuofRdL1sdXD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        },
        "outputId": "a9a27e17-c03d-407c-8b2f-9e57d5862fa3"
      },
      "source": [
        "print(df_val2.head())\n",
        "# del df_val2['index']\n",
        "df_val2=df_val2.reset_index(drop=True)\n",
        "df_val2.head()"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                label  ... labels\n",
            "8750           canada  ...      6\n",
            "8751        AskReddit  ...      0\n",
            "8752  leagueoflegends  ...     12\n",
            "8753       conspiracy  ...      7\n",
            "8754           hockey  ...     11\n",
            "\n",
            "[5 rows x 3 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>canada</td>\n",
              "      <td>gt this purchase benefit ontarians way it done...</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>AskReddit</td>\n",
              "      <td>they come color cows either answer correct</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>leagueoflegends</td>\n",
              "      <td>https twitter com tsmdoublelift status steve g...</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>conspiracy</td>\n",
              "      <td>at point i think bot intelligent offense war c...</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>hockey</td>\n",
              "      <td>oh i see thanks dissecting frog clue worked be...</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             label                                               text  labels\n",
              "0           canada  gt this purchase benefit ontarians way it done...       6\n",
              "1        AskReddit         they come color cows either answer correct       0\n",
              "2  leagueoflegends  https twitter com tsmdoublelift status steve g...      12\n",
              "3       conspiracy  at point i think bot intelligent offense war c...       7\n",
              "4           hockey  oh i see thanks dissecting frog clue worked be...      11"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9Grbnt8MRnJ",
        "colab_type": "text"
      },
      "source": [
        "ULMFiT language model fine tuning+ classifier training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-LfbqFuuVc-C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_lm = TextLMDataBunch.from_df(train_df = df_trn, valid_df = df_val,text_cols='text',label_cols='label',path = \"\",min_freq=2)\n",
        "\n",
        "# Classifier model data\n",
        "data_clas = TextClasDataBunch.from_df(path = \"\", train_df = df_trn, valid_df = df_val, vocab=data_lm.train_ds.vocab, test_df=test,text_cols='text',label_cols='label',bs=32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47gbWL8TViSR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "69a35f3b-31de-46dc-9b8e-f2cc68692cfd"
      },
      "source": [
        "learn = language_model_learner(data_lm, AWD_LSTM, drop_mult=0.9)\n",
        "learn.fit_one_cycle(cyc_len=1, max_lr=1e-2)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>7.195064</td>\n",
              "      <td>6.818326</td>\n",
              "      <td>0.116551</td>\n",
              "      <td>03:40</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-OfUR-uVpV7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "outputId": "1f8188a9-b216-40b0-9294-f312c591c9f2"
      },
      "source": [
        "learn.unfreeze()\n",
        "learn.fit_one_cycle(cyc_len=3, max_lr=2e-3)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>6.628860</td>\n",
              "      <td>6.493684</td>\n",
              "      <td>0.139868</td>\n",
              "      <td>04:17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>6.434684</td>\n",
              "      <td>6.354203</td>\n",
              "      <td>0.150131</td>\n",
              "      <td>04:16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>6.128782</td>\n",
              "      <td>6.325001</td>\n",
              "      <td>0.153109</td>\n",
              "      <td>04:16</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UpItx6E-Vs8B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn.save_encoder('ft_enc')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dT-B0Zx-V1qO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "73a10cb1-be33-4e22-a5ba-67a74a223bea"
      },
      "source": [
        "learn = text_classifier_learner(data_clas,AWD_LSTM, drop_mult=0.9)\n",
        "learn.load_encoder('ft_enc')\n",
        "\n",
        "learn.freeze()\n",
        "learn.fit_one_cycle(1, slice(2e-3/100, 2e-3))"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>1.990416</td>\n",
              "      <td>1.639660</td>\n",
              "      <td>0.500571</td>\n",
              "      <td>02:41</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ezd-vgV3V22o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "08e11556-d365-4380-f55d-57606ad845eb"
      },
      "source": [
        "learn.freeze_to(-2)\n",
        "learn.fit_one_cycle(1, slice(2e-3/100, 2e-3))"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>1.976006</td>\n",
              "      <td>1.599307</td>\n",
              "      <td>0.513857</td>\n",
              "      <td>03:23</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_SKOxiwj07R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "a04f7a47-0c60-4391-c6a3-7a879644cbe3"
      },
      "source": [
        "learn.freeze_to(-3)\n",
        "learn.fit_one_cycle(1, slice(2e-3/100, 2e-3))"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>1.815203</td>\n",
              "      <td>1.542576</td>\n",
              "      <td>0.532286</td>\n",
              "      <td>04:32</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOatAugej5S4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "outputId": "92a6b63b-0723-4055-9fe1-71d3e555ba46"
      },
      "source": [
        "learn.unfreeze()\n",
        "learn.fit_one_cycle(10, slice(2e-3/100, 2e-3))\n"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='8' class='' max='10', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      80.00% [8/10 56:17<14:04]\n",
              "    </div>\n",
              "    \n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>1.851728</td>\n",
              "      <td>1.518229</td>\n",
              "      <td>0.535571</td>\n",
              "      <td>06:40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.781112</td>\n",
              "      <td>1.514887</td>\n",
              "      <td>0.543571</td>\n",
              "      <td>07:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.732981</td>\n",
              "      <td>1.490845</td>\n",
              "      <td>0.549714</td>\n",
              "      <td>07:41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.654869</td>\n",
              "      <td>1.464984</td>\n",
              "      <td>0.557000</td>\n",
              "      <td>07:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.627550</td>\n",
              "      <td>1.445955</td>\n",
              "      <td>0.566000</td>\n",
              "      <td>06:35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.536946</td>\n",
              "      <td>1.437045</td>\n",
              "      <td>0.565286</td>\n",
              "      <td>06:54</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>1.505937</td>\n",
              "      <td>1.433024</td>\n",
              "      <td>0.566571</td>\n",
              "      <td>07:14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>1.505341</td>\n",
              "      <td>1.422740</td>\n",
              "      <td>0.569571</td>\n",
              "      <td>06:57</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='436' class='' max='1968', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      22.15% [436/1968 01:35<05:34 1.4391]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Buffered data was truncated after reaching the output size limit."
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VSI5PuAykfb6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_predsulm, _ = learn.get_preds(DatasetType.Valid,ordered=True)\n",
        "val2_predsulm, _ = learn.get_preds(DatasetType.Test,ordered=True)\n",
        "val1_predsulm=val1_predsulm.numpy()\n",
        "val2_predsulm=val2_predsulm.numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_fa9YLFgQWU_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_predsulm, _ = learn.get_preds(DatasetType.Test,ordered=True)\n",
        "test_predsulm=test_predsulm.numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rPVmPoKl8Mo9",
        "colab": {}
      },
      "source": [
        "#defining tf-idf vectorizer\n",
        "cv_unigram_tfidf = TfidfVectorizer(lowercase=True,\n",
        "                     stop_words=stop_words,\n",
        "                     analyzer='word',\n",
        "                     ngram_range = (1,1),\n",
        "                     tokenizer = preprocess,\n",
        "                    binary=False)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "htyUS7kL8MpQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0c6a7ef9-e76f-4ed3-e935-29c3686e4fbf"
      },
      "source": [
        "sample=int(0.5*len(x_val))\n"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8750\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Hkk-VHHx8Mpc",
        "colab": {}
      },
      "source": [
        "x_val1=x_val[:sample]\n",
        "x_val2=x_val[sample:]\n",
        "y_val1=y_val[:sample]\n",
        "y_val2=y_val[sample:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YJ8QLDRRZWpJ",
        "outputId": "5eb4ddc4-b20a-47ef-b4c6-f9e1e79b774d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "source": [
        "#training and validation data\n",
        "x_train_unigram_tfidf = cv_unigram_tfidf.fit_transform(x_train)\n",
        "x_val_unigram_tfidf = cv_unigram_tfidf.transform(x_val)\n",
        "x_val1_unigram_tfidf = cv_unigram_tfidf.transform(x_val1)\n",
        "x_val2_unigram_tfidf = cv_unigram_tfidf.transform(x_val2)\n",
        "x_test_unigram_tfidf=cv_unigram_tfidf.transform(x_comments_test)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['doe', 'ha', 'wa'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "H6RCvTn6QH7v",
        "colab": {}
      },
      "source": [
        "optim=Adam(lr=0.0001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "r48oeRrRQHBZ"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jBuLCskaNG1n",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0db948a8-dcad-44c3-d78c-c5fe5aa5bb6c"
      },
      "source": [
        "knn=KNeighborsClassifier(n_neighbors=250,algorithm='auto',weights='distance')\n",
        "t1=time.time()\n",
        "knn.fit(x_train_unigram_tfidf1, y)\n",
        "time.time()-t1\n",
        "# x=knn.predict_proba(x_train_unigram_tfidf)\n",
        "# y=knn.predict_proba(x_val_unigram_tfidf)\n",
        "# knn.fit(x_train_unigram_tfidf, y_train)\n",
        "# print(knn.score(x_val_unigram_tfidf, y_val))"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.020282745361328125"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wEYYYsq8Ibch",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "b1a0b570-58a8-4e81-ed22-766f66a7be9f"
      },
      "source": [
        "#creating final training data.\n",
        "x_train_unigram_tfidf1 = cv_unigram_tfidf.fit_transform(x_comments_train)\n",
        "x_test_unigram_tfidf=cv_unigram_tfidf.transform(x_comments_test)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['doe', 'ha', 'wa'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3ReiCBY0EF86",
        "colab": {}
      },
      "source": [
        "#SVM initial training\n",
        "sg=SGDClassifier(loss='hinge',alpha=1e-4,max_iter=1000)\n",
        "csg = CalibratedClassifierCV(base_estimator=sg, method='isotonic', cv=3)\n",
        "csg.fit(x_train_unigram_tfidf,y_train)\n",
        "svtrpred=csg.predict_proba(x_train_unigram_tfidf)\n",
        "svvalpred=csg.predict_proba(x_val_unigram_tfidf)\n",
        "svval1pred=csg.predict_proba(x_val1_unigram_tfidf)\n",
        "svval2pred=csg.predict_proba(x_val2_unigram_tfidf)\n",
        "\n",
        "# print(csg.score(x_val_unigram_tfidf, y_val))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0g6-zbOBK6z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0a31ec46-860b-4a58-8ca0-2e8bf2a0e989"
      },
      "source": [
        "#svm final training on whole dataset\n",
        "sg=SGDClassifier(loss='hinge',alpha=1e-4,max_iter=1000)\n",
        "csg = CalibratedClassifierCV(base_estimator=sg, method='isotonic', cv=3)\n",
        "t1=time.time()\n",
        "csg.fit(x_train_unigram_tfidf1,y)\n",
        "print(time.time()-t1)\n",
        "svtestpred=csg.predict_proba(x_test_unigram_tfidf)\n",
        "# print(csg.score(x_val_unigram_tfidf, y_val))"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5.38595724105835\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXFcThsoBbiG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "outputId": "d88979f4-5d72-4aa1-91a3-06b5cf760525"
      },
      "source": [
        "#logistic regression initial training\n",
        "lr1 = LogisticRegression(max_iter=300,C=1)\n",
        "lr1.fit(x_train_unigram_tfidf, y_train)\n",
        "lrtrpred=lr1.predict_proba(x_train_unigram_tfidf)\n",
        "lrvalpred=lr1.predict_proba(x_val_unigram_tfidf)\n",
        "lrval1pred=lr1.predict_proba(x_val1_unigram_tfidf)\n",
        "lrval2pred=lr1.predict_proba(x_val2_unigram_tfidf)\n",
        "\n",
        "print(lr1.score(x_val_unigram_tfidf, y_val))\n"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
            "  \"this warning.\", FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_5rlVC1bUryZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "outputId": "5e1ce87b-9960-4a82-f3a0-e09398cfaeeb"
      },
      "source": [
        "#final logistic regression on whole data\n",
        "lr1 = LogisticRegression(max_iter=300,C=1)\n",
        "t1=time.time()\n",
        "lr1.fit(x_train_unigram_tfidf1, y)\n",
        "print(time.time()-t1)\n",
        "lrtestpred=lr1.predict_proba(x_test_unigram_tfidf)\n",
        "# print(lr1.score(x_val_unigram_tfidf, y_val))\n"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
            "  \"this warning.\", FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "18.42897653579712\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wx9S1RsqBkLN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# initial naive bayes training\n",
        "\n",
        "nb3 = MultinomialNB(alpha=0.18) \n",
        "nb3.fit(x_train_unigram_tfidf, y_train)\n",
        "nbtrpred=nb3.predict_proba(x_train_unigram_tfidf)\n",
        "nbvalpred=nb3.predict_proba(x_val_unigram_tfidf)\n",
        "nbval1pred=nb3.predict_proba(x_val1_unigram_tfidf)\n",
        "nbval2pred=nb3.predict_proba(x_val2_unigram_tfidf)\n",
        "# print(nb3.score(x_val_unigram_tfidf, y_val))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0wsmy73V8Mpn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9fe66589-8197-4c31-af94-7da2922bb0d8"
      },
      "source": [
        "# final naive bayes training on whole dataset\n",
        "\n",
        "nb3 = MultinomialNB(alpha=0.18)\n",
        "t1=time.time()\n",
        "nb3.fit(x_train_unigram_tfidf1, y)\n",
        "print(time.time()-t1)\n",
        "nbtestpred=nb3.predict_proba(x_test_unigram_tfidf)\n",
        "# print(nb3.score(x_val_unigram_tfidf, y_val))"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.1432945728302002\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xf5ZNKLXBy-A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#concatenation of validation split predictions for training meta classifier\n",
        "pred_val=np.concatenate((svvalpred,lrvalpred,nbvalpred,val_predsum),axis=1)\n",
        "pred_val1=np.concatenate((svval1pred,lrval1pred,nbval1pred,val1_predsulm),axis=1)\n",
        "pred_val2=np.concatenate((svval2pred,lrval2pred,nbval2pred,val2_predsulm),axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pHuISXD_w8Bg",
        "colab": {}
      },
      "source": [
        "#concatenation of test data probabilities predictions for training meta classifier\n",
        "predtest=np.concatenate((svtestpred,lrtestpred,nbtestpred,test_predsulm),axis=1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QXXQllAlOmv7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pkl_filename = \"/content/drive/My Drive/reddit-comment-classification-comp-551/lr_model.pkl\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O6zak22hpFsc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#training and testing meta classifier on the split validation of stacked model on data split in ratio 75-25%\n",
        "lr1=LogisticRegression()\n",
        "lr1.fit(pred_val1,y_val1)\n",
        "lr1.score(pred_val2,y_val2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TQwgYZmezKML",
        "outputId": "020ddb15-4bbc-4d53-c262-530eb0a39919",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "source": [
        "#final training of meta classifier and saving it for later\n",
        "lr=LogisticRegression()\n",
        "lr.fit(pred_val,y_val)\n",
        "# print(lr.score(pred_val2,y_val2))\n",
        "\n",
        "with open(pkl_filename, 'wb') as file:\n",
        "    pickle.dump(lr, file)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
            "  \"this warning.\", FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.5954285714285714\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NOc8OMjfOVkj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(pkl_filename, 'rb') as file:\n",
        "    lr = pickle.load(file)\n",
        "preds=lr.predict(predtest)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qWmGM0KmmXaD",
        "outputId": "ad927091-503c-4325-9db4-53109f8e388c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "source": [
        "#ensemble classfier without ULMFiT\n",
        "# for voting dont fit the naive bayes and logistic only define them\n",
        "eclf1 = VotingClassifier(estimators=[('lr1', lr1), ('nb', nb3),('sg',csg)], voting='soft')\n",
        "eclf1 = eclf1.fit(x_train_unigram_tfidf, y_train)\n",
        "print(eclf1.score(x_val_unigram_tfidf, y_val))\n",
        "# print(eclf1.score(x_train_unigram_tfidf, y_train))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
            "  \"this warning.\", FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.5780571428571428\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mkv2rwGNofdx",
        "outputId": "2674a7d3-56b2-47f1-a1db-ded11cd45cc5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "source": [
        "#final prediction using ensemble classifier\n",
        "eclf1 = VotingClassifier(estimators=[\n",
        "...         ('lr', lr1), ('nb', nb3),('sg',csg)], voting='soft')\n",
        "eclf1 = eclf1.fit(x_train_unigram_tfidf1, y)\n",
        "# print(eclf1.score(x_val_unigram_tfidf, y_val))\n",
        "# print(eclf1.score(x_train_unigram_tfidf1, y))\n",
        "preds=eclf1.predict(x_test_unigram_tfidf)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
            "  \"this warning.\", FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.8226\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Q06YOvmP8MqY",
        "colab": {}
      },
      "source": [
        "#making csv for kaggle test data\n",
        "ids=[]\n",
        "labels=[]\n",
        "\n",
        "for i in range(preds.shape[0]):\n",
        "    ids.append(i)\n",
        "    labels.append(index_to_labels[preds[i]])\n",
        "out_df=pd.DataFrame({'Id':ids,\n",
        "                    'Category':labels})\n",
        "order=['Id','Category']\n",
        "out_df[order].to_csv('/content/drive/My Drive/reddit-comment-classification-comp-551/test3.csv',index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}